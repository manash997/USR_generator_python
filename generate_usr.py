#Open file parser-output.txt which is generated by running isc-parser
#store the contents into parser_output_lines 



#Open the parser file,and store its contents into a 2d-list
parser_output_list=[]
with open("txt_files/parser-output.txt","r",encoding="UTF-8") as pf:
    parser_output_lines=pf.readlines()
parser_output_lines.pop()
#we append the lines into a list thereby it is 2d list parser_output_list
for line in parser_output_lines:
    parser_output_list.append(line.split())

#Open pruner file and store all its words into a 2d list
prune_output_list=[]
with open("txt_files/prune-output.txt","r",encoding="UTF-8") as pf:
    prune_output_lines=pf.readlines()
#we append the lines into a list thereby it is 2d list prune_output_list
for line in prune_output_lines:
    prune_output_list.append(line.split())

#open wx file and append it into a list
wx_output_list=[]
with open("txt_files/wx.txt","r",encoding="UTF-8") as pf:
    wx_list=pf.readlines()
    wx_output_list=wx_list[0].split()
root_word_dict={} #this is a dictionary where key is root word and value is original word
wx_length=len(wx_output_list)
morph_output_list=prune_output_lines[3:wx_length+2]
for line in morph_output_list:#creating a root-word dictionary
    vm_row=line.split()[4]
    vm_row_split=vm_row.split(",")
    root_word=vm_row_split[0][4:]
    original_word_wx=line.split()[1]
    root_word_dict[root_word]=original_word_wx
#print(root_word_dict)
#Creating a dictionary for wx_words and their indexes
wx_words_dictionary={}
index=1
for words in wx_output_list:
    wx_words_dictionary[index]=words
    index+=1
temp_wx_words_dict=wx_words_dictionary#temporary for loop usage
#print(wx_words_dictionary)
#------------------------------------------------------------------------
#creating a dictionary for parser_output_list
parser_output_dict={}
index=1
for par_value in parser_output_list:
    parser_output_dict[index]=par_value
    index+=1
#print(parser_output_dict)
#--------------------------------------------------------------------
concept_list=[]
used_root_word=set()
updated_root_word={}
info_list_final=[] #list containing important values from parser output file
for line in parser_output_list:
    info_list_temp=[]
    word_index=int(line[0])
    pos_tag=line[3]
    class_index=line[6]
    word_info=line[7]
    info_list_temp.append(word_index)
    info_list_temp.append(pos_tag)
    info_list_temp.append(class_index)
    info_list_temp.append(word_info)
    info_list_final.append(info_list_temp)
#for line in info_list_final:
#    print(line)
#--------------------------------------------------------------------
#To print 1st row of USR which is the Original Sentence
def get_row1():
    row1="#"
    for p_list in parser_output_list:
      row1=row1+" "+p_list[1]
    return row1

#To generate groups,"Not clear about it's output.please refer"
group_list=[]
index=len(parser_output_list)
for val in range(index):
    if val==index-1 or parser_output_list[val][7]=="pof" or parser_output_list[val][7]=="pof__cn":
        group_list.append("0")
        #print(parser_output_list[val][1])
    elif parser_output_list[val][7]=="lwg__psp":
        group_list.append("-1")
        #print(parser_output_list[val][1])
    else:
        group_list.append("1")
        #print(parser_output_list[val][1])
 

#Row 2 of USR Which is Concept 
#for every element in wx_output_list,check its POS TAG
#the third column in parser_output_list[][3] is POS TAG,index from 0

def get_8th_vector(word):
    for line in morph_output_list:
        if word in line:
            vm_row=line.split()[4]
            vm_row_split=vm_row.split(",")
            vector_8th=vm_row_split[7][:-2].partition("'")[0]
    return vector_8th
        
def get_root_word(word):
    for key2,value2 in root_word_dict.items():
                if value2==word:
                    root_word=key2
                    break
    return root_word
def for_handling_nnc_tag_or_pof(word,class_index):
    root_word=get_root_word(word)
    class_word=wx_words_dictionary[class_index]
    root_word_class=get_root_word(class_word)
    if root_word_class in used_root_word:
        root_word_class=updated_root_word[root_word_class]
        concept_list.remove(updated_root_word[root_word_class])
        updated_root_word[root_word_class]=root_word+"+"+root_word_class

        
    else:
        used_root_word.add(root_word_class)
        updated_root_word[root_word_class]=root_word+"+"+root_word_class
    return root_word+"+"+root_word_class
def get_row2():
    
    already_visited={}
    
    counter=0
    for word in wx_output_list:
        for key,value in wx_words_dictionary.items():
            if value==word:
                word_index=int(key) #word index of the word in wx_list
        for line in info_list_final:
            if word_index in line:
                pos_tag=line[1]
                class_index=int(line[2])
                word_info=line[3]
        #main condition check begins here
        if pos_tag=="PSP" or pos_tag=="NST" or pos_tag=="SYM":
            continue
        elif pos_tag=="VM":
            
            root_word=get_root_word(word)
            vector_8th=get_8th_vector(word)
            if root_word in used_root_word:
                final_word=updated_root_word[root_word]+"-"+vector_8th
                concept_list.remove(updated_root_word[root_word])
            else:
                final_word=root_word+"-"+vector_8th

            for line in info_list_final[word_index:-1]:
                pos_tag=line[1]
                if pos_tag=="VAUX":
                    word_index=line[0]
                    temp=wx_words_dictionary[word_index]
                    final_word=final_word+"_"+temp
                    already_visited[temp]=1
                else:
                    break
            concept_list.append(final_word)
        elif pos_tag=="VAUX" and already_visited[word]==1:
            continue
        elif pos_tag=="NNC" or word_info=="pof":

            final_word=for_handling_nnc_tag_or_pof(word,class_index)
            concept_list.append(final_word)
        else:
            root_word=get_root_word(word)
            concept_list.append(root_word+"_1")
        counter+=1
    return concept_list


    

#Row 3 of USR:Index for concepts
def get_row3(concept_list):
    index_for_concepts=[]
    for ind in range(len(concept_list)):
        index_for_concepts.append(ind+1)
    return index_for_concepts

#Row 4 of USR:Semantic category of Nouns
def get_row4():
    wx_index=1
    sem_category_list=[]
    for vax in range(len(prune_output_lines)):
        if "NER" in prune_output_lines[vax]:
            break
    NER_list=prune_output_lines[vax:-1]
    def get_sem_cat(wx_index):
        for value4 in range(len(NER_list)):
            flag=0
            wx_index_str=str(wx_index)
            if wx_index_str in NER_list[value4] and "person" in NER_list[value4]:
                sem_category_list.append("per")
                flag=0
                break
            elif wx_index_str in NER_list[value4] and "location" in NER_list[value4]:
                sem_category_list.append("loc")
                flag=0
                break
            elif wx_index_str in NER_list[value4] and "organization" in NER_list[value4]:
                sem_category_list.append("org")
                flag=0
                break
            else:
                flag=1
        if flag==1:    
            sem_category_list.append('')
        return sem_category_list

    for wx_index in range(1,len(wx_output_list)):
        sem_category_list=get_sem_cat(wx_index)
    return sem_category_list
    
#Row 5 :Gender,Number,Person Information only for nouns(NN tag in parser)
def get_row5():
    def get_af(eng_word):
        for index1 in range(len(prune_output_lines)):
            if eng_word in prune_output_lines[index1]:
                vm_row=prune_output_lines[index1].split()
                row_vector=vm_row[4]
                return row_vector
                break
    gnp_vector_list=[]  
    for value1 in range(len(parser_output_list)):
        if parser_output_list[value1][7] in ("r6","k7","k1","k2","k7p","ras-k1","k2p","r6-k2","k5","rt"):
            eng_word=wx_output_list[value1]
            gnp_vector=get_af(eng_word)
            gnp_vector_list.append(gnp_vector.split(",")[1:4])

    
    for value3 in range(len(gnp_vector_list)):
        for i in range(0,3):
            if gnp_vector_list[value3][i]=="1":
                gnp_vector_list[value3][i]="u"
            elif gnp_vector_list[value3][i]=="2":
                gnp_vector_list[value3][i]="m"
            elif gnp_vector_list[value3][i]=="3":
                gnp_vector_list[value3][i]="a"
            elif gnp_vector_list[value3][i]=="any":
                gnp_vector_list[value3][i]="-"
    return gnp_vector_list
#Row 6:Dependencies

def get_row2_index(word):
    for concept in range(len(row_2)):
        if word in row_2[concept]:
            return concept+1

def get_row6(row_2):
    row_6=[]
    row2_iter=[]#a list which is cleaned part of row2 to be worked upon
    row2_wx_index_iter=[]#list which has correct indexes of words in row_2
    class_word_index_list=[]#list which contains indexes of all class_words
    class_word_index_dict={}
    class_word_list=[]#list of class words from their indexexes in wx_format
    root_word_from_wx=[]#list of root words from their wx words
    dependency_col7_list=[]#list of col7 values in parser output
    correct_index_list=[]#list of final indexexs of dependencies in row2
    #print(row_2)
    for concepts in row_2:
        if "+" in concepts:
            concepts=concepts.split("+")[1]
        if "-" in concepts:
            concepts=concepts.split("-")[0]
        concepts=concepts.split("_")[0]
        row2_iter.append(concepts)
    #print(row2_iter) #iterable after cleaning
    
    for root_word in row2_iter:
        wx_word=root_word_dict.get(root_word)
        #print(wx_word)
        for key,value in temp_wx_words_dict.items():
            if value==wx_word:
                wx_word_inx=key
                value=0
        row2_wx_index_iter.append(wx_word_inx)
    
    #print(row2_wx_index_iter) #indexes for same wx words
    
    for index_value in row2_wx_index_iter:
        par_value=parser_output_dict[index_value]
        class_word_index=int(par_value[6])
        dependency=par_value[7]
        class_word_index_list.append(class_word_index)
        dependency_col7_list.append(dependency)
    #print(class_word_index_list)
    
    
    for index_6 in class_word_index_list:
        #do something about index_6==0 here
        if index_6==0:
            class_word_list.append(0)
        else:
            class_word_list.append(wx_words_dictionary[index_6])    
            
       # print(index_6)
    #print(class_word_list)
    for word in class_word_list:
        if word==0:
            root_word_from_wx.append(0)
        for key,value in root_word_dict.items():
            if value==word:
                root_word_from_wx.append(key)
    #print(root_word_from_wx)
    #Now we have to find,where this word is in row_2 and get that index
    for word in root_word_from_wx:
        if word==0:
            correct_index_list.append(0)
            continue
        correct_index=get_row2_index(word)
        correct_index_list.append(correct_index)
    #print(correct_index_list)
    #print(dependency_col7_list)
    for val in range(len(dependency_col7_list)):
        if dependency_col7_list[val]=="main":
            row_6.insert(val,"0:main")
        else:
            index_6a=str(correct_index_list[val])
            row_6.append(index_6a+":"+dependency_col7_list[val])

    return row_6

#Row 10:Sentence type
def get_row10():
    sentence_type=[]
    if "nahI" in wx_output_list or "nahIM" in wx_output_list:
        sentence_type.append('negative')
    else:
        if "?" in wx_output_list:
            sentence_type.append("interrogative")
        elif "|" in wx_output_list:
            sentence_type.append("affirmative")
    return sentence_type

if __name__=="__main__":
    row_1=get_row1()
    row_2=get_row2()
    row_3=get_row3(row_2)
    row_4=get_row4()
    row_5=get_row5()
    row_6=get_row6(row_2)
    row_10=get_row10()
    print(row_1)
    print(row_2)
    print(row_3)
    print(row_4)
    print(row_5)
    print(row_6)
    print("")
    print("")
    print("")
    print(row_10)


        
        

        







  






    





    


    
