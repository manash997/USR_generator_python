#Open file parser-output.txt which is generated by running isc-parser
#store the contents into parser_output_lines 
from unicodedata import name

#Open the parser file,and store its contents into a 2d-list
parser_output_list=[]
with open("txt_files/parser-output.txt","r",encoding="UTF-8") as pf:
    parser_output_lines=pf.readlines()
parser_output_lines.pop()
#we append the lines into a list thereby it is 2d list parser_output_list
for line in parser_output_lines:
    parser_output_list.append(line.split())

#Open pruner file and store all its words into a 2d list
prune_output_list=[]
with open("txt_files/prune-output.txt","r",encoding="UTF-8") as pf:
    prune_output_lines=pf.readlines()
#we append the lines into a list thereby it is 2d list prune_output_list
for line in prune_output_lines:
    prune_output_list.append(line.split())

#open wx file and append it into a list
wx_output_list=[]
with open("txt_files/wx.txt","r",encoding="UTF-8") as pf:
    wx_list=pf.readlines()
    wx_output_list=wx_list[0].split()

#To print 1st row of USR which is the Original Sentence
def get_row1():
    row1="#"
    for p_list in parser_output_list:
      row1=row1+" "+p_list[1]
    return row1

#To generate groups,"Not clear about it's output.please refer"
group_list=[]
index=len(parser_output_list)
for val in range(index):
    if val==index-1 or parser_output_list[val][7]=="pof" or parser_output_list[val][7]=="pof__cn":
        group_list.append("0")
        #print(parser_output_list[val][1])
    elif parser_output_list[val][7]=="lwg__psp":
        group_list.append("-1")
        #print(parser_output_list[val][1])
    else:
        group_list.append("1")
        #print(parser_output_list[val][1])
 

#Row 2 of USR Which is Concept 
#for every element in wx_output_list,check its POS TAG
#the third column in parser_output_list[][3] is POS TAG,index from 0
def get_row2():
    #writing a function for finding rootword of the token from prune_output_lines
    def for_finding_rootword_in_prune(token):
        for index in range(len(prune_output_lines)):
                if token in prune_output_lines[index]:
                    vm_row=prune_output_lines[index].split()
                    row_vector=vm_row[4]
                    row_vector_split=row_vector.split(",")
                    root_word=row_vector_split[0][4:]+"_1"
                    return root_word
                    break
    #for every word which is a class-word,add it to a seperate list.Since it has been concatenated and root word derived so no need to handle it except for VM tags.
    #for every element in wx_output_list,check its POS TAG
    #the third column in parser_output_list[][3] is POS TAG,index from 0
    concept_list=[]
    alr_visited_bit=[]
    class_word_list=[]
    for inx in range(1,len(wx_output_list)):
        alr_visited_bit.append(0)
    vaux_counter=0

    def for_handling_vmtag(token,root_word_modified,flag):
        for index in range(len(prune_output_lines)):
                if token in prune_output_lines[index]:
                    vm_row=prune_output_lines[index].split()
                    row_vector=vm_row[4]
                    row_vector_split=row_vector.split(",")
                    root_word=row_vector_split[0][4:]+"_1" #deriving root word from the row_vector_split
                    vector_8th=row_vector_split[7][:-2].partition("'")[0] #derive 8th vector from row_vector_split
                    if flag==0:
                        return root_word+"-"+vector_8th
                    else:
                        return root_word_modified+"-"+vector_8th
                    break
                    
    def for_handling_nnc_tag_or_pof(token,class_index):
        for index in range(len(prune_output_lines)):
            if token in prune_output_lines[index]:
                vm_row=prune_output_lines[index].split()
                row_vector=vm_row[4]
                row_vector_split=row_vector.split(",")
                root_word=row_vector_split[0][4:]+"_1"
                class_word=wx_output_list[class_index-1]
                class_word_list.append(class_word)
                #find the root word for the class_word
                root_word_class=for_finding_rootword_in_prune(class_word)
                break
        return root_word+"+"+root_word_class

            
    def for_handling_other_tag(token):
        return for_finding_rootword_in_prune(token)
                

        
    #for every root-word add _1 to it
    #if pos-tag is NNC,check its number in 6th column and club it with that "+" ,_1
    #if info is pof then check the number in 6th col. left of it and club it with it "+"               
    for index2 in range(len(wx_output_list)):
        token=wx_output_list[index2]
        pos_tag=parser_output_list[index2][3]
        word_info=parser_output_list[index2][7]
        class_index=int(parser_output_list[index2][6])
        if pos_tag=="PSP" or pos_tag=="NST" or pos_tag=="SYM":
            continue
        #here we handle the verb group i.e VM tag
        elif pos_tag=="VM":
            flag=0
            root_word_modified="0"
            for word in concept_list:
                if token in word:
                    root_word_modified=word
                    flag=1
                    break
            token=for_handling_vmtag(token,root_word_modified,flag)
            #here we concatenate remaining vaux tag words to our output,search remaining list and concatenate following vaux tags
            next_index=index2+1
            for temp in wx_output_list[next_index:-1]:
                pos_tag=parser_output_list[next_index][3]
                if pos_tag=="VAUX":
                    alr_visited_bit[next_index]=1
                    token="_"+temp if token is None else token+"_"+temp
                    next_index+=1
                else:
                    break
            if flag==0:
                concept_list.append(token)
            else:
                concept_list.remove(root_word_modified)
                concept_list.append(token)
            #break
        elif token in class_word_list:
            continue
        elif pos_tag=="VAUX" and alr_visited_bit[index2]==1:
            continue

        elif pos_tag=="NNC" or word_info=="pof":
            token=for_handling_nnc_tag_or_pof(token,class_index)
            concept_list.append(token)
        


        else:
            token=for_handling_other_tag(token)
            concept_list.append(token)
        
    return concept_list


    

#Row 3 of USR:Index for concepts
def get_row3(concept_list):
    index_for_concepts=[]
    for ind in range(len(concept_list)):
        index_for_concepts.append(ind+1)
    return index_for_concepts

#Row 4 of USR:Semantic category of Nouns
def get_row4():
    wx_index=1
    sem_category_list=[]
    for vax in range(len(prune_output_lines)):
        if "NER" in prune_output_lines[vax]:
            break
    NER_list=prune_output_lines[vax:-1]
    def get_sem_cat(wx_index):
        for value4 in range(len(NER_list)):
            flag=0
            wx_index_str=str(wx_index)
            if wx_index_str in NER_list[value4] and "person" in NER_list[value4]:
                sem_category_list.append("per")
                flag=0
                break
            elif wx_index_str in NER_list[value4] and "location" in NER_list[value4]:
                sem_category_list.append("loc")
                flag=0
                break
            elif wx_index_str in NER_list[value4] and "organization" in NER_list[value4]:
                sem_category_list.append("org")
                flag=0
                break
            else:
                flag=1
        if flag==1:    
            sem_category_list.append('')
        return sem_category_list

    for wx_index in range(1,len(wx_output_list)):
        sem_category_list=get_sem_cat(wx_index)
    return sem_category_list
    
#Row 5 :Gender,Number,Person Information only for nouns(NN tag in parser)
def get_row5():
    def get_af(eng_word):
        for index1 in range(len(prune_output_lines)):
            if eng_word in prune_output_lines[index1]:
                vm_row=prune_output_lines[index1].split()
                row_vector=vm_row[4]
                return row_vector
                break
    gnp_vector_list=[]  
    for value1 in range(len(parser_output_list)):
        if parser_output_list[value1][7] in ("r6","k7","k1","k2","k7p","ras-k1","k2p","r6-k2","k5","rt"):
            eng_word=wx_output_list[value1]
            gnp_vector=get_af(eng_word)
            gnp_vector_list.append(gnp_vector.split(",")[1:4])

    
    for value3 in range(len(gnp_vector_list)):
        for i in range(0,3):
            if gnp_vector_list[value3][i]=="1":
                gnp_vector_list[value3][i]="u"
            elif gnp_vector_list[value3][i]=="2":
                gnp_vector_list[value3][i]="m"
            elif gnp_vector_list[value3][i]=="3":
                gnp_vector_list[value3][i]="a"
            elif gnp_vector_list[value3][i]=="any":
                gnp_vector_list[value3][i]="-"
    return gnp_vector_list

#Row 10:Sentence type
def get_row10():
    sentence_type=[]
    if "nahI" in wx_output_list or "nahIM" in wx_output_list:
        sentence_type.append('negative')
    else:
        if "?" in wx_output_list:
            sentence_type.append("interrogative")
        elif "|" in wx_output_list:
            sentence_type.append("affirmative")
    return sentence_type

if __name__=="__main__":
    row_1=get_row1()
    row_2=get_row2()
    row_3=get_row3(row_2)
    row_4=get_row4()
    row_5=get_row5()
    row_10=get_row10()
    print(row_1)
    print(row_2)
    print(row_3)
    print(row_4)
    print(row_5)
    print(row_10)


        
        

        







  






    





    


    
